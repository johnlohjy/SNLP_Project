{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9c9a4378-8415-4acf-96ba-5fe7e5fd1f3b",
      "metadata": {
        "id": "9c9a4378-8415-4acf-96ba-5fe7e5fd1f3b"
      },
      "source": [
        "### Tutorial From\n",
        "\n",
        "1. https://mccormickml.com/2019/09/19/XLNet-fine-tuning/\n",
        "2. https://medium.com/swlh/using-xlnet-for-sentiment-classification-cfa948e65e85"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enabling GPU in Google Colab\n",
        "\n",
        "1. Go to 'Runtime' tab\n",
        "2. Click on 'Change runtime type'\n",
        "3. Select GPU"
      ],
      "metadata": {
        "id": "jfUtzeAYJaQ4"
      },
      "id": "jfUtzeAYJaQ4"
    },
    {
      "cell_type": "markdown",
      "id": "d50ae906-0bf4-44d8-b434-57725d3ac929",
      "metadata": {
        "id": "d50ae906-0bf4-44d8-b434-57725d3ac929"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Keras-Preprocessing"
      ],
      "metadata": {
        "id": "0bwPjAYJC4S3",
        "outputId": "8648a4ef-7389-407d-d0d8-0998c926e7b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0bwPjAYJC4S3",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Keras-Preprocessing in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.25.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "97dccc61-85c8-4487-b7e9-019c0ee5c821",
      "metadata": {
        "id": "97dccc61-85c8-4487-b7e9-019c0ee5c821"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import XLNetTokenizer, XLNetModel, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from collections import defaultdict\n",
        "\n",
        "from torch import nn, optim\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset,RandomSampler,SequentialSampler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "652445ad-67d2-4d03-8ac3-6ce225d56246",
      "metadata": {
        "id": "652445ad-67d2-4d03-8ac3-6ce225d56246"
      },
      "outputs": [],
      "source": [
        "# Find out difference between pytorch_transformers vs transformers\n",
        "from transformers import XLNetForSequenceClassification"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use Google Colab GPU if available"
      ],
      "metadata": {
        "id": "O8A7wm5KEz5d"
      },
      "id": "O8A7wm5KEz5d"
    },
    {
      "cell_type": "code",
      "source": [
        "# Return a bool indicating if CUDA is currently available.\n",
        "if torch.cuda.is_available():\n",
        "  # Use CUDA-enabled GPU\n",
        "  device = torch.device(\"cuda:0\")\n",
        "  print(\"GPU is Available\")\n",
        "  torch.cuda.empty_cache()\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"GPU is Not Available. Use CPU\")"
      ],
      "metadata": {
        "id": "VDlg7P1XFNgE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2033f0a-3f92-4ba7-d0ff-79c13483ee67"
      },
      "id": "VDlg7P1XFNgE",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is Not Available. Use CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab4314e7-dc83-4fa3-81e4-1ab5f52ad5c5",
      "metadata": {
        "id": "ab4314e7-dc83-4fa3-81e4-1ab5f52ad5c5"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "486b20ca-83b6-46cf-907c-e22a00e0756c",
      "metadata": {
        "id": "486b20ca-83b6-46cf-907c-e22a00e0756c"
      },
      "outputs": [],
      "source": [
        "# Read Training Dataset\n",
        "# https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92\n",
        "filepath_train = 'https://raw.githubusercontent.com/johnlohjy/SNLP_Project/XLNet_John/data/train_2024.csv'\n",
        "df = pd.read_csv(filepath_train, quoting=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3977f39a-063a-4079-b743-41c58b031f2f",
      "metadata": {
        "id": "3977f39a-063a-4079-b743-41c58b031f2f",
        "outputId": "85498a74-45de-4b4f-d140-288211027417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                               text  label\n",
              "0   0  Except that Desmond played first base last nig...      0\n",
              "1   1  What i find funny is the loyalty and blindness...      0\n",
              "2   2  Read the article  not just the headline & you ...      0\n",
              "3   3  Speaking of a horses backside  is that where y...      1\n",
              "4   4  Michael Barone- gee are you dumb.  No other wo...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c93259f8-2888-4070-a1c5-181eb82b2368\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Except that Desmond played first base last nig...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>What i find funny is the loyalty and blindness...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Read the article  not just the headline &amp; you ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Speaking of a horses backside  is that where y...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Michael Barone- gee are you dumb.  No other wo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c93259f8-2888-4070-a1c5-181eb82b2368')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c93259f8-2888-4070-a1c5-181eb82b2368 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c93259f8-2888-4070-a1c5-181eb82b2368');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-999b0eab-b21e-48d0-884d-520e68924cb4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-999b0eab-b21e-48d0-884d-520e68924cb4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-999b0eab-b21e-48d0-884d-520e68924cb4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 99000,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28578,\n        \"min\": 0,\n        \"max\": 98999,\n        \"num_unique_values\": 99000,\n        \"samples\": [\n          1054,\n          28607,\n          30862\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 98998,\n        \"samples\": [\n          \"I really  really want to believe that we will actually follow up and vote these people out of office this year. I don't have much hope  but I want to believe it's true...\",\n          \"Sorry ! They're Illegal ! Do you think Illegal Canadians would be welcome in Somalia ? Large Somali population in Minnesota assisted by Somalians to come to Canada = Ahmed Hussen Canadian Immigration Minister who happens to be from Somalia ! No wonder the RCMP are carrying their luggage ! Canada is Screwed and we know it !\",\n          \"please grow up  no one needs dumb ideas  see lunatic its not the government doing any of this\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# View head of training dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "add2aa70-508a-4c21-a3cd-00b4d7f57025",
      "metadata": {
        "id": "add2aa70-508a-4c21-a3cd-00b4d7f57025"
      },
      "source": [
        "### Pre-Process Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e3a7d4d7-0ec2-43fb-8654-b40b48402a6c",
      "metadata": {
        "id": "e3a7d4d7-0ec2-43fb-8654-b40b48402a6c"
      },
      "outputs": [],
      "source": [
        "# Step 1: Get sentences\n",
        "sentences = list(df.loc[:, 'text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d9e3f65d-a2a7-4169-bd6f-4ea4136e48f9",
      "metadata": {
        "id": "d9e3f65d-a2a7-4169-bd6f-4ea4136e48f9"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Step 2: Add Sepcial tokens [SEP] (end of sentence token) and [CLS] (classification token) to the end of sequences first\n",
        "https://datascience.stackexchange.com/questions/66207/what-is-purpose-of-the-cls-token-and-why-is-its-encoding-output-important\n",
        "https://towardsdatascience.com/fastai-with-transformers-bert-roberta-xlnet-xlm-distilbert-4f41ee18ecb2\n",
        "https://huggingface.co/docs/transformers/model_doc/xlnet#xlnettokenizer\n",
        "\"\"\"\n",
        "sentences = [sentence + \" [SEP] [CLS]\" for sentence in sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "174c84d1-f9bd-4ded-9285-2e69eb91ef50",
      "metadata": {
        "id": "174c84d1-f9bd-4ded-9285-2e69eb91ef50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e4e8d37-ad93-444d-9400-547efc5673de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Step 3: Initialise tokenizer\n",
        "Initialise word tokenizer to be used\n",
        "SentencePiece Tokenizer is used by XLNetTokenizer. It can handle all words, special characters and spaces easily\n",
        "https://huggingface.co/docs/transformers/en/tokenizer_summary#sentencepiece\n",
        "https://aman.ai/primers/ai/tokenizer/#sentencepiece\n",
        "\"\"\"\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
        "\n",
        "# Step 4: Tokenize Text\n",
        "tokenized_text = [tokenizer.tokenize(sent) for sent in sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3893d83b-d87f-4c02-a360-901ac97226e4",
      "metadata": {
        "id": "3893d83b-d87f-4c02-a360-901ac97226e4"
      },
      "outputs": [],
      "source": [
        "# Viewing tokenized text\n",
        "for i in range(5):\n",
        "    print(tokenized_text[i])\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b132b3a4-2441-4ce6-b625-45806771dbca",
      "metadata": {
        "id": "b132b3a4-2441-4ce6-b625-45806771dbca"
      },
      "outputs": [],
      "source": [
        "# Get max length of the sequence\n",
        "MAX_LEN = max(len(sent) for sent in tokenized_text)\n",
        "\n",
        "print(\"The Max Length of a Sentence is: \")\n",
        "print(MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f36ed61-da38-4070-beba-8344ca914ccd",
      "metadata": {
        "id": "2f36ed61-da38-4070-beba-8344ca914ccd"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Step 5: Prepare inputs for XLNet\n",
        "1) Input IDs\n",
        "   - Seq of integers identifying each input token (from our tokenized text) to its index number in the XLNet tokenizer vocabulary\n",
        "\n",
        "2) Attention Mask\n",
        "   - Helps the model to focus on actual words vs padding\n",
        "\n",
        "3) Labels\n",
        "\"\"\"\n",
        "\n",
        "# Use the XLNet tokenizer to convert the tokens to their index numbers in the XLNet vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(token) for token in tokenized_text]\n",
        "\n",
        "# Pad the sequence using keras. Truncate: if len of sequence is less than our MAX_LEN, we cut it from the back\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create the attention masks\n",
        "attention_masks = []\n",
        "for sequence in input_ids:\n",
        "    sequence_masked = [float(i>0) for i in sequence]\n",
        "    attention_masks.append(sequence_masked)\n",
        "\n",
        "labels = list(df.loc[:, 'label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19cba16f-1d49-4a83-bf2f-85804b467b78",
      "metadata": {
        "id": "19cba16f-1d49-4a83-bf2f-85804b467b78"
      },
      "outputs": [],
      "source": [
        "print(len(input_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a214699a-def9-48e5-bfa3-df17bc4bd283",
      "metadata": {
        "id": "a214699a-def9-48e5-bfa3-df17bc4bd283"
      },
      "outputs": [],
      "source": [
        "print(len(attention_masks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb4db30c-0f72-40d7-b10c-5a47df8843ba",
      "metadata": {
        "id": "cb4db30c-0f72-40d7-b10c-5a47df8843ba"
      },
      "outputs": [],
      "source": [
        "print(len(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddeeb02e-05db-4816-8d2e-2c10df35bf31",
      "metadata": {
        "id": "ddeeb02e-05db-4816-8d2e-2c10df35bf31"
      },
      "source": [
        "### Initialise the PyTorch DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5646e222-e482-4468-8cf8-40eed7bde823",
      "metadata": {
        "id": "5646e222-e482-4468-8cf8-40eed7bde823"
      },
      "outputs": [],
      "source": [
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "\n",
        "# Provide the same method for splitting, random state and test size so that inputs and masks match\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels,\n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d82e41c2-8604-4729-b3ed-ccd6a7cc2488",
      "metadata": {
        "id": "d82e41c2-8604-4729-b3ed-ccd6a7cc2488"
      },
      "outputs": [],
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0f17002-1e7e-49f6-8c35-a8ce027ea08f",
      "metadata": {
        "id": "b0f17002-1e7e-49f6-8c35-a8ce027ea08f"
      },
      "outputs": [],
      "source": [
        "# Select a batch size for training. For fine-tuning with XLNet, the authors recommend a batch size of\n",
        "# 32, 48, or 128. We will use 32 here to avoid memory issues.\n",
        "batch_size = 32\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop,\n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "# Use TensorDataset to make a tuple of sample (train_inputs, train_masks, train_labels)\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "# Shuffle the training samples by randomly sampling the data\n",
        "train_sampler = RandomSampler(train_data)\n",
        "# DataLoader wraps an iterable around to enable easy access to the samples\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "# Sample in a fixed, sequential order\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68988495-b07a-4d4d-854a-988305adb7fa",
      "metadata": {
        "id": "68988495-b07a-4d4d-854a-988305adb7fa"
      },
      "source": [
        "### Initialise the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b551cd8-3fc8-407a-a162-be157858dd92",
      "metadata": {
        "id": "1b551cd8-3fc8-407a-a162-be157858dd92"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Load the model: XLNEtForSequenceClassification, the pretrained XLNet model with an added single linear classification layer on top.\n",
        "\n",
        "As we feed input data, the entire pre-trained XLNet model and the additional untrained classification layer is trained on our specific task.\n",
        "\"\"\"\n",
        "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the model to the specified device\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "yVFM4ZgrH_a2"
      },
      "id": "yVFM4ZgrH_a2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b44ba522-07bf-478a-9534-5fa019c2c410",
      "metadata": {
        "id": "b44ba522-07bf-478a-9534-5fa019c2c410"
      },
      "outputs": [],
      "source": [
        "# Display model's current parameters\n",
        "print(\"Model's current parameters:\")\n",
        "model_parameters = list(model.named_parameters())\n",
        "for parameter in model_parameters:\n",
        "    print(\"Parameter name: \" + parameter[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "486798f2-5c0b-47e9-9108-25d335668e5e",
      "metadata": {
        "id": "486798f2-5c0b-47e9-9108-25d335668e5e"
      },
      "outputs": [],
      "source": [
        "# Define a set of different parameters for AdamW to optimise\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "\n",
        "# Which parameters should undergo weight decay and at what rate. Find out more later\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [parameter for name, parameter in model_parameters if not any(no_decay_parameters in name for no_decay_parameters in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "\n",
        "    {'params': [parameter for name, parameter in model_parameters if any(no_decay_parameters in name for no_decay_parameters in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "# Initialise the optimzer\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b51174b-f26a-4465-b2d8-c8a84728a8a7",
      "metadata": {
        "id": "7b51174b-f26a-4465-b2d8-c8a84728a8a7"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f93b3f9f-43b9-40fc-a3e9-93036756031b",
      "metadata": {
        "id": "f93b3f9f-43b9-40fc-a3e9-93036756031b"
      },
      "outputs": [],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d69dbaa-dcc9-4f6d-afbd-17dbc2817978",
      "metadata": {
        "id": "8d69dbaa-dcc9-4f6d-afbd-17dbc2817978"
      },
      "outputs": [],
      "source": [
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for i in range(epochs):\n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "\n",
        "  # Initialise epoch loss\n",
        "  epoch_loss = 0\n",
        "\n",
        "  # Train the data for one epoch\n",
        "  for batch_number, batch in enumerate(train_dataloader):\n",
        "    # Pass data to the specified device as well\n",
        "    batch = tuple(data.to(device) for data in batch)\n",
        "\n",
        "    # Unpack the inputs from our dataloader\n",
        "    batch_input_ids, batch_input_mask, batch_labels = batch\n",
        "\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    # Call optimizer.zero_grad() to reset the gradients of model parameters. Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteration\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    # See https://huggingface.co/docs/transformers/v4.39.1/en/model_doc/xlnet#transformers.XLNetForSequenceClassification\n",
        "    # See https://huggingface.co/docs/transformers/en/model_doc/xlnet#transformers.models.xlnet.modeling_xlnet.XLNetForSequenceClassificationOutput\n",
        "    outputs = model(batch_input_ids, token_type_ids=None, attention_mask=batch_input_mask, labels=batch_labels)\n",
        "    loss = outputs[0]\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "    # Backward pass\n",
        "    # Compute derivatives of loss function wrt parameters\n",
        "    # When doing backward propagation, PyTorch accumulates the gradients, i.e. the value of computed gradients is added to the grad property of all leaf nodes of computational graph\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    # Adjust the parameters by the gradients collected in the backward pass\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  print(\"Loss for epoch \" + str(i+1) + \" is: \" + str(epoch_loss / len(train_dataloader)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a5NQ37-PPqmA"
      },
      "id": "a5NQ37-PPqmA",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}